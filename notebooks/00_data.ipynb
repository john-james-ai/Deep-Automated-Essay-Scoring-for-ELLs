{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "The dataset (the ELLIPSE corpus) comprises argumentative essays written by 8th-12th grade English Language Learners (ELLs). The essays have been scored according to six analytic measures: cohesion, syntax, vocabulary, phraseology, grammar, and conventions. Each measure represents a component of proficiency in essay writing, with greater scores corresponding to greater proficiency in that measure. The scores range from 1.0 to 5.0 in increments of 0.5. The task is to predict the score of each of the six measures for the essays given in the test set.\n",
    "\n",
    "**File and Field Information**\n",
    "train.csv - The training set, comprising the full_text of each essay, identified by a unique text_id. The essays are also given a score for each of the seven analytic measures above: cohesion, etc. These analytic measures comprise the target for the competition.    \n",
    "test.csv - For the test data we give only the full_text of an essay together with its text_id.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import logging.config\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from atelier.workflow.pipeline import DataPipeBuilder, DataPipe\n",
    "from atelier.data.io import YamlIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "sns.set_palette(\"Blues_r\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "# Pandas\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "# Configurations\n",
    "ETL_CONFIG_FILE = \"config/etl.yml\"\n",
    "LOGGING_CONFIG_FILE = \"config/logging.yml\"\n",
    "DATA_CONFIG_FILE = \"config/data.yml\"\n",
    "FEATURE_CONFIG_FILE = \"config/features.yml\"\n",
    "# Logging\n",
    "io =  YamlIO()\n",
    "LOGGING_CONFIG = io.read(LOGGING_CONFIG_FILE)\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "logger = logging.getLogger(__name__)\n",
    "# Data Directories\n",
    "DATA_DIRECTORIES = io.read(DATA_CONFIG_FILE)['directories']\n",
    "FEATURE_STORE = io.read(FEATURE_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Transform and Load\n",
    "The following data pipeline obtains and prepares the data for profiling, analysis, and downstream feature engineering, and modeling. In short the data pipeline,    \n",
    "\n",
    "1. Extracts the data from the Kaggle website, unpacks, and stores it locally in the raw data directory. \n",
    "2. Transforms the raw data into tokens, tags the associated parts-of-speech, and parses the syntactic dependencies for syntactic analysis.  \n",
    "3. Loads the raw and transformed data into the local environment for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = DataPipeBuilder()                     \n",
    "builder.build(ETL_CONFIG_FILE)           \n",
    "datapipe = builder.pipeline                     \n",
    "datapipe.run()                                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Profile\n",
    "This data profile step examines the structure, types, nullability, cardinality, statistics, and distributions of the dataset to illuminate data quality issues, so that corrective action can be undertaken before downstream investments in analysis, feature engineering, and modeling are committed.  Let's start with the training set. \n",
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3911 entries, 0 to 3910\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   text_id      3911 non-null   object \n",
      " 1   full_text    3911 non-null   object \n",
      " 2   cohesion     3911 non-null   float64\n",
      " 3   syntax       3911 non-null   float64\n",
      " 4   vocabulary   3911 non-null   float64\n",
      " 5   phraseology  3911 non-null   float64\n",
      " 6   grammar      3911 non-null   float64\n",
      " 7   conventions  3911 non-null   float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 244.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_filepath = os.path.join(DATA_DIRECTORIES['raw'], 'train.csv')\n",
    "train = pd.read_csv(train_filepath)\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a shape [3911,8] and no null values. Our identity variable, text_id, and the full_text are string objects and our target variables are float values.  Let's examine a few random samples.\n",
    "### Random Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>394F5867B7EC</td>\n",
       "      <td>Working alone is great but have you ever thought about the benefits of working in groups? for ex...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>598C1E9B27C8</td>\n",
       "      <td>Your character will be what you yourself choose to make. Do we choose our own character traits, ...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>F584D9BB5F5C</td>\n",
       "      <td>\" Has the limitation of human contact due to the use of technology had a positive or negative af...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>A4F11F4A76AE</td>\n",
       "      <td>Students should enjoy summer break, cause they would not have to worry about school and they can...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>529A633179FF</td>\n",
       "      <td>Have you ever wondered about the important's and the difference between imagination and knowledg...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id  \\\n",
       "743   394F5867B7EC   \n",
       "1158  598C1E9B27C8   \n",
       "3653  F584D9BB5F5C   \n",
       "2212  A4F11F4A76AE   \n",
       "1077  529A633179FF   \n",
       "\n",
       "                                                                                                full_text  \\\n",
       "743   Working alone is great but have you ever thought about the benefits of working in groups? for ex...   \n",
       "1158  Your character will be what you yourself choose to make. Do we choose our own character traits, ...   \n",
       "3653  \" Has the limitation of human contact due to the use of technology had a positive or negative af...   \n",
       "2212  Students should enjoy summer break, cause they would not have to worry about school and they can...   \n",
       "1077  Have you ever wondered about the important's and the difference between imagination and knowledg...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
       "743       3.50    3.00        3.50         3.50     2.50         3.00  \n",
       "1158      3.00    3.50        3.50         3.00     4.00         4.00  \n",
       "3653      4.00    3.50        3.50         4.00     3.00         3.50  \n",
       "2212      2.50    2.50        3.00         2.50     3.00         3.50  \n",
       "1077      3.00    3.50        4.00         3.50     3.00         3.50  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(train.shape[0], size=5)\n",
    "train.loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at some text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Do you think first impressions are impossible to change ? In my opinion a first impression on someone or something change be changed, because you never know what the stereotype of the thing can be.\\n\\nWhen you first meet someone your first impression on the person can be one thing but you never know what the person could have. For example you see a fat guy or female and you can be quick to judge them but you don't know anything about there life, till when you talk to them and get to know their true story that they medical conditions on why they are the way the appear and look like. You could meet a Hispanic, For example you might thing they came to US illegally, but you don't really know that some Hispanic are actually born in the united states and are legal citizens. when you see a Asian person you may think there smart because of your first impression stereotype, but not all Asian are actually smart and appear to who you really think they are.\\n\\nNext is the type of thing you purchase or are going to purchase, it can look nice and be expensive but you dont know the background story on the item or thing you are going to purchase. For example when you want to purchase a car or house, you can be looking at it on the internet and like it a lot but once you buy it you start noticing strange thing. If it is the car you realize the its starting to give you a lot of problems that you are constantly taking money out you'r pocket to try to fix it to your expectations and what were your first impression on the car being nice and reliable. Second a house you're impression where \"oh wow this is a really nice house\", so you go on and purchase it the you start realizing that the house was making wired noises at night while you are trying to sleep, Then one day you go online and contact the landowner or research the history of the house and realize the house is haunted because the original owner past away their.\\n\\nA first impression is just a stereotype or judgment that you think of someone or something before not know the background story on it. Before you go and be quick to judge some based on their looks talk to the person see why they are really the way they look before making fun of them of talk about them because everyone in this world isnt perfect and everything has a story behind it.     \n",
       "1297    Do you think the greatest accomplishment in the world is to be yourself in a world that is trying to change the person you are?, because I do not think people should change themself ever for what god brought us in the world for who we are and not changing ourself for others. So yes, I agree with Emerson statement about individuality, because people in this world are trying to change themselfs for others or just changing themselfs because they dont like themselfs for who they are. There are so many reasons why I agree with this statement especially in today's society that most people in this world are changging themselfs for someone else. I don't agree with the fact that people have the courage to change for others, because in any case they should just be thereselfs and love them for who they are, is the greatest accomplishment and feeling ever.\\n\\nIt is the greatest accomplishment because of the feeling that you loved yourself and secceeded without someone bringing you down and making you change yourself is the best feeling to feel. Otherwise the people who are trying to bring you down are winning and you are giving them the power that they should not have. In today's generation with all the social media we have people that have been rude and comment someting bad to make you feel bad about yourself and then some people change themself just because of a comment that could hurt someone. But if you can secceed people will leave you alone, because they know you will not listen to the rude comments you would recive and there just wasting there time. So then you have the power and accomplished the negetivity that people are trying to change yourself.\\n\\nAlso being yourself does not mean you wont have mistakes because everyone does and that is okay just without you changging yourself and accomplishing thing is the best part of life. It is okay to have mistakes because everyone learns from them and next thing they will do better then the last time they did something bad or had a mistake. People will go through tough times but it does not mean you should automatically change yourself for that. Everyone goes threw a situation that they probebly think they hate themself and wanna change the person they are, but I think that is wrong and they should be thereselfs and understand that everything will be alright at the end without them trying to change themselfs.\\n\\nIn my opinion I do not think that changing yourself will help with anything and I think it would probebly make things worst. LIke for an example if you change yourself nothing is gonna happend just you letting yourself down and changing who you are that should not have been in that situation. Also people would most likely notice and ask why you change yourself and that would bring back memories and make you go back in time and see why you change yourself. But if you dont change yourslef no one would know and wont bring up any badly past back memories. Also mistakes can happend and if you change yourself and go back and see old pictuers of you of how you used to be you might not like for who you are now and you cant go back because you change yourself for someone you did not want to be I mean you could always try but why try after you did it and cant go back.\\n\\nSo just be you and do not change for others who are constantly trying to make you something else who it is'nt you. It is such an amazing feeling and more people in this world would be great if they would'nt change for someone else because they would get the confidence and not worrying about what others has to say about them. People would most likely be so positive if they would be themself and not changing constantly or ever themselfs for people who are ignorent. People who love you would never say to change the person you are because that is just wrong and they know that they would not want to lose you as the person you are. So in all saying that everyone should not change and be themselfs in a world that is constantly trying to change them. \n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 5000)\n",
    "idx = np.random.randint(train.shape[0], size=2)\n",
    "train['full_text'].loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that the data are organized by paragraphs denoted by double linebreak characters. This may be useful for establishing sentence boundaries during preprocessing; however, they should be removed prior to the modeling stage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Descriptive Statistics\n",
    "Let's get a sense of the target variable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cohesion</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syntax</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocabulary</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phraseology</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  mean  std  min  25%  50%  75%  max\n",
       "cohesion    3,911.00  3.13 0.66 1.00 2.50 3.00 3.50 5.00\n",
       "syntax      3,911.00  3.03 0.64 1.00 2.50 3.00 3.50 5.00\n",
       "vocabulary  3,911.00  3.24 0.58 1.00 3.00 3.00 3.50 5.00\n",
       "phraseology 3,911.00  3.12 0.66 1.00 2.50 3.00 3.50 5.00\n",
       "grammar     3,911.00  3.03 0.70 1.00 2.50 3.00 3.50 5.00\n",
       "conventions 3,911.00  3.08 0.67 1.00 2.50 3.00 3.50 5.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = train[['cohesion', 'syntax', 'vocabulary', 'phraseology',\t'grammar',\t'conventions']]\n",
    "scores.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Distribution Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scores are in the range [1,5] and are centered on the mean of 3.0. Next, we examine surface features such as word length, sentence, length, frequency measures within the texts.\n",
    "\n",
    "### Surface Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number words</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>430.49</td>\n",
       "      <td>191.87</td>\n",
       "      <td>14.00</td>\n",
       "      <td>294.00</td>\n",
       "      <td>402.00</td>\n",
       "      <td>526.50</td>\n",
       "      <td>1,260.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number types</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>165.45</td>\n",
       "      <td>56.72</td>\n",
       "      <td>13.00</td>\n",
       "      <td>124.00</td>\n",
       "      <td>158.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>439.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTR</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Letters per word</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number paragraphs</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>103.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of sentences</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of words per sentence</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>28.88</td>\n",
       "      <td>25.41</td>\n",
       "      <td>6.34</td>\n",
       "      <td>17.89</td>\n",
       "      <td>22.50</td>\n",
       "      <td>31.43</td>\n",
       "      <td>565.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>determiners</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demonstratives</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of pronouns</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first person pronouns</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second person pronouns</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third person pronouns</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conjuncts</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectives</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negations</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future</th>\n",
       "      <td>3,911.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count   mean    std   min    25%    50%  \\\n",
       " number words                 3,911.00 430.49 191.87 14.00 294.00 402.00   \n",
       " number types                 3,911.00 165.45  56.72 13.00 124.00 158.00   \n",
       " TTR                          3,911.00   0.41   0.08  0.15   0.35   0.40   \n",
       " Letters per word             3,911.00   4.26   0.28  3.30   4.07   4.26   \n",
       " number paragraphs            3,911.00  10.08   6.23  1.00   7.00   9.00   \n",
       " number of sentences          3,911.00  18.80  10.49  1.00  11.00  17.00   \n",
       " number of words per sentence 3,911.00  28.88  25.41  6.34  17.89  22.50   \n",
       "determiners                   3,911.00   0.08   0.03  0.00   0.06   0.08   \n",
       "demonstratives                3,911.00   0.02   0.01  0.00   0.01   0.02   \n",
       "number of pronouns            3,911.00   0.10   0.04  0.00   0.07   0.10   \n",
       "first person pronouns         3,911.00   0.03   0.03  0.00   0.01   0.02   \n",
       "second person pronouns        3,911.00   0.03   0.03  0.00   0.00   0.02   \n",
       "third person pronouns         3,911.00   0.03   0.02  0.00   0.01   0.03   \n",
       "conjuncts                     3,911.00   0.00   0.01  0.00   0.00   0.00   \n",
       "connectives                   3,911.00   0.06   0.02  0.00   0.04   0.05   \n",
       "negations                     3,911.00   0.02   0.01  0.00   0.01   0.01   \n",
       "future                        3,911.00   0.02   0.02  0.00   0.01   0.02   \n",
       "\n",
       "                                 75%      max  \n",
       " number words                 526.50 1,260.00  \n",
       " number types                 198.00   439.00  \n",
       " TTR                            0.46     0.93  \n",
       " Letters per word               4.44     5.60  \n",
       " number paragraphs             11.00   103.00  \n",
       " number of sentences           25.00   100.00  \n",
       " number of words per sentence  31.43   565.50  \n",
       "determiners                     0.10     0.23  \n",
       "demonstratives                  0.03     0.10  \n",
       "number of pronouns              0.12     0.23  \n",
       "first person pronouns           0.05     0.22  \n",
       "second person pronouns          0.05     0.20  \n",
       "third person pronouns           0.05     0.18  \n",
       "conjuncts                       0.01     0.04  \n",
       "connectives                     0.07     0.15  \n",
       "negations                       0.02     0.07  \n",
       "future                          0.03     0.11  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytics = pd.read_csv(FEATURE_STORE['sinlp'], index_col=None)[[ ' number words', ' number types', ' TTR', ' Letters per word',\n",
    "       ' number paragraphs', ' number of sentences',\n",
    "       ' number of words per sentence', 'determiners', 'demonstratives',\n",
    "       'number of pronouns', 'first person pronouns', 'second person pronouns',\n",
    "       'third person pronouns', 'conjuncts', 'connectives', 'negations',\n",
    "       'future']]\n",
    "analytics.describe().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('aes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "634215c1768fe5e7f4dff3c32019033fc4260ccb6bad5e9329bf88c312891f8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
